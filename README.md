# Analysis-Of-Secured-Federated-Learning
A detailed analysis of secured Federated Learning

# Motivation 
A promising method for data privacy in industries like healthcare, finance or closed domain tasks is federated learning (FL). Due to its ability to train machine learning models on decentralized data sources without compromising privacy, it has garnered a lot of interest and attention.

The implementation of FL in the healthcare sector enables various healthcare providers to exchange confidential patient information, fostering collaborative research and improving patient outcomes. FL meets with the requirement to add an additional layer of data protection, allowing healthcare firms to utilise enormous amounts of data while maintaining patient privacy.

Financial institutions are also beginning to recognize the value of FL for improving their products and decreasing fraud. In this manner, they can use FL to analyze patterns and trends in client behavior without endangering the privacy of sensitive financial data. 

# Introduction 
Although FL is a step in the right direction toward data privacy, there are still many issues and difficulties with it. The subject of how vulnerable FL still is must be addressed because there are numerous applications for FL where FL is used as a privacy approach. Our study aims to delve further into the issue by examining two different privacy strategiesâ€”FL and FL with DP.

By carefully examining these two privacy measures, our work attempts to shed insight on their effectiveness and drawbacks. This study will aid in the understanding of the benefits and drawbacks of Federated learning as a privacy approach by advancing the enormous body of research on FL through the application of diverse data privacy assaults.


